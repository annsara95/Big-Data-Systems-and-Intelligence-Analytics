{"cells":[{"cell_type":"code","source":["df = sqlContext.read.format('csv').load('/FileStore/tables/modifiedStockData.csv')"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df = df.filter(df._c0. isNotNull())"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["df = df.drop(df._c0)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["df = (df.withColumnRenamed(\"_c1\",\"open\").withColumnRenamed(\"_c2\",\"high\").withColumnRenamed(\"_c3\",\"low\").withColumnRenamed(\"_c4\",\"close\").withColumnRenamed(\"_c5\",\"adj_close\").withColumnRenamed(\"_c6\",\"volume\").withColumnRenamed(\"_c7\",\"year\").withColumnRenamed(\"_c8\",\"month\").withColumnRenamed(\"_c9\",\"date\"))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["df = (df.withColumn('open',df.open.cast('float')).withColumn('high',df.high.cast('float')).withColumn('low',df.low.cast('float')).withColumn('close',df.close.cast('float')).withColumn('adj_close',df.adj_close.cast('float')).withColumn('volume',df.volume.cast('double')).withColumn('year',df.year.cast('int')).withColumn('month',df.month.cast('int')).withColumn('date',df.date.cast('int')))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["df.columns"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["stages=[]\nnumcols = ['high','low','close','adj_close','volume','year','month','date']"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["assembler = VectorAssembler(inputCols=numcols, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["pipeline = Pipeline(stages=stages)\npipelineModel = pipeline.fit(df)\ndf = pipelineModel.transform(df)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["(trainingData, testData) = df.randomSplit([0.7, 0.3], seed = 100)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\nlogit = LinearRegression(featuresCol='features',labelCol='open')\nfit = logit.fit(trainingData)\npredictions = fit.transform(testData)\npredictions.select(\"prediction\", \"open\", \"features\").show(5)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n# Select (prediction, true label) and compute test error\nevaluator = RegressionEvaluator(\n    labelCol=\"open\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.regression import GeneralizedLinearRegression\nglr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3,featuresCol='features',labelCol='open')\nmodel = glr.fit(trainingData)\nglr_testPred = model.transform(testData)\nglr_testPred.select(\"prediction\", \"open\", \"features\").show(5)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# Select (prediction, true label) and compute test error\nglrevaluator = RegressionEvaluator(\n    labelCol=\"open\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = glrevaluator.evaluate(glr_testPred)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.regression import RandomForestRegressor\n# Train a RandomForest model.\nrf = RandomForestRegressor(featuresCol='features',labelCol='open')\nrffit = rf.fit(trainingData)\nrftest_pred = rffit.transform(testData)\nrftest_pred.select(\"prediction\", \"open\", \"features\").show(5)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n# Select (prediction, true label) and compute test error\nrfevaluator = RegressionEvaluator(labelCol=\"open\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = rfevaluator.evaluate(rftest_pred)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"ML Proj BDIA","notebookId":2530957896222593},"nbformat":4,"nbformat_minor":0}
